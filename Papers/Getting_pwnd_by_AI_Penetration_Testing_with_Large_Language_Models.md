## Getting pwnâ€™d by AI: Penetration Testing with Large Language Models (Dec. 2023)
[Database:](https://dl-acm-org.ezproxy.semo.edu:2443/doi/10.1145/3611643.3613083) DOI: [10.1145/3611643.3613083](https://dl.acm.org/doi/10.1145/3611643.3613083)

[PDF](https://dl-acm-org.ezproxy.semo.edu:2443/doi/pdf/10.1145/3611643.3613083) 

### Goal: This paper explores the potential use of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. 

We explore two distinct use cases: high-level task planning for security testing assignments and low level vulnerability hunting within a vulnerable virtual machine
	
	
## Main Topics: (State of the Art)

### Approach

### Solutions
Issue: lack of personnel

#### Large language models (LLMs) - ChatCPT or GPT3.5

Experimented asking LLM to help design penetration tests for both generic scenarios and concrete target organization

* Use: help design penetration tests, generate phishing or vishing messages, automated report generation (for pen-test and red teaming)

### Tools

#### MITRE ATT&CK: curated database of knowledge about threat actors in the cybersecurity domain
* covers different tactics, techniques, and procedures

	
### Methods (ex: Raspberry Pi)
To showcase low-level guidance, we integrated GPT3.5 with a vulnerable virtual machine and allowed it to analyze the machine for vulnerabilities and suggest attack vectors

### Misc


### Other Documents Referenced

#### [Mitre att&ck: Design and philosophy (2018)](https://www.mitre.org/news-insights/publication/mitre-attck-design-and-philosophy)

Citation: 

Blake E Strom, Andy Applebaum, Doug P Miller, Kathryn C Nickels, Adam G
Pennington, and Cody B Thomas. 2018. Mitre att&ck: Design and philosophy. In
Technical report. The MITRE Corporation